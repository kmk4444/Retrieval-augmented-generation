{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPoWqnTNJaQFK26/Wyszabl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmk4444/Retrieval-augmented-generation/blob/main/Part2_basic_rag_with_langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will develop url RAG using langchain. Also, we will use google gemini api key for llm and cohere api key for embeddings."
      ],
      "metadata": {
        "id": "PsW0QxJQkcWJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Requirements.txt**"
      ],
      "metadata": {
        "id": "LiIrSQrlkzzN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NpWHfAMVi4N-"
      },
      "outputs": [],
      "source": [
        "!touch requirements.txt\n",
        "!echo langchain >> requirements.txt\n",
        "!echo langchain-openai >> requirements.txt\n",
        "!echo openai >> requirements.txt\n",
        "!echo langchain-google-genai >> requirements.txt\n",
        "!echo cohere >> requirements.txt\n",
        "!echo faiss-cpu >> requirements.txt\n",
        "!echo streamlit >> requirements.txt\n",
        "!echo python-dotenv >> requirements.txt\n",
        "!echo llama-index >> requirements.txt\n",
        "!echo pypdf >> requirements.txt\n",
        "!echo chromadb >> requirements.tx\n",
        "!echo beautifulsoup4 >> requirements.tx\n",
        "!echo matplotlib >> requirements.tx\n",
        "!echo rank_bm25 >> requirements.tx\n",
        "!echo replicate >> requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bash/command**"
      ],
      "metadata": {
        "id": "SiJ_dRHQk3Og"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "TlgUVcC7kZvP",
        "outputId": "18e07871-3148-4761-8c1a-e452ad4e56df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.35->llama-index->-r requirements.txt (line 9)) (1.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit->-r requirements.txt (line 7)) (1.16.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain->-r requirements.txt (line 1))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai->-r requirements.txt (line 4)) (1.63.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai->-r requirements.txt (line 4)) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai->-r requirements.txt (line 4)) (0.1.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai->-r requirements.txt (line 4)) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai->-r requirements.txt (line 4)) (1.63.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai->-r requirements.txt (line 4)) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai->-r requirements.txt (line 4)) (3.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai->-r requirements.txt (line 4)) (0.6.0)\n",
            "Installing collected packages: striprtf, dirtyjson, watchdog, types-requests, smmap, python-dotenv, pypdf, packaging, orjson, mypy-extensions, jsonpointer, httpx-sse, h11, fastavro, faiss-cpu, deprecated, typing-inspect, tiktoken, pydeck, marshmallow, jsonpatch, httpcore, gitdb, langsmith, httpx, gitpython, dataclasses-json, replicate, openai, llamaindex-py-client, langchain-core, cohere, streamlit, llama-index-legacy, llama-index-core, langchain-text-splitters, langchain-openai, langchain-community, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, langchain, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, langchain-google-genai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed cohere-5.3.5 dataclasses-json-0.6.5 deprecated-1.2.14 dirtyjson-1.0.8 faiss-cpu-1.8.0 fastavro-1.9.4 gitdb-4.0.11 gitpython-3.1.43 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 httpx-sse-0.4.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.19 langchain-community-0.0.38 langchain-core-0.1.52 langchain-google-genai-1.0.3 langchain-openai-0.1.6 langchain-text-splitters-0.0.1 langsmith-0.1.56 llama-index-0.10.35 llama-index-agent-openai-0.2.4 llama-index-cli-0.1.12 llama-index-core-0.10.35.post1 llama-index-embeddings-openai-0.1.9 llama-index-indices-managed-llama-cloud-0.1.6 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.18 llama-index-multi-modal-llms-openai-0.1.5 llama-index-program-openai-0.1.6 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.22 llama-index-readers-llama-parse-0.1.4 llama-parse-0.4.2 llamaindex-py-client-0.1.19 marshmallow-3.21.2 mypy-extensions-1.0.0 openai-1.27.0 orjson-3.10.3 packaging-23.2 pydeck-0.9.0 pypdf-4.2.0 python-dotenv-1.0.1 replicate-0.25.2 smmap-5.0.1 streamlit-1.34.0 striprtf-0.0.26 tiktoken-0.6.0 types-requests-2.31.0.20240406 typing-inspect-0.9.0 watchdog-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores.faiss import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import CohereEmbeddings\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "#load_dotenv()\n",
        "#my_key_google = os.getenv(\"google_apikey\")\n",
        "#my_key_cohere = os.getenv(\"cohere_apikey\")\n",
        "\n",
        "#for google colab\n",
        "my_key_google=\"---\"\n",
        "my_key_cohere=\"----\"\n",
        "\n",
        "llm_gemini = ChatGoogleGenerativeAI(google_api_key=my_key_google, model=\"gemini-pro\")\n",
        "embeddings = CohereEmbeddings(cohere_api_key=my_key_cohere,model=\"embed-multilingual-v3.0\")\n",
        "\n",
        "def ask_gemini(prompt):\n",
        "\n",
        "    AI_Response = llm_gemini.invoke(prompt)\n",
        "\n",
        "    return AI_Response.content\n",
        "\n",
        "def rag_with_url(target_url, prompt):\n",
        "  loader=WebBaseLoader(target_url)\n",
        "  raw_documents = loader.load()\n",
        "\n",
        "  text_splitter = RecursiveCharacterTextSplitter(\n",
        "      chunk_size=1000,\n",
        "      chunk_overlap=0,\n",
        "      length_function=len\n",
        "  )\n",
        "\n",
        "  splitted_documents = text_splitter.split_documents(raw_documents)\n",
        "\n",
        "  vectorstore = FAISS.from_documents(splitted_documents,embeddings)\n",
        "  retriever = vectorstore.as_retriever()\n",
        "\n",
        "  relevant_documents = retriever.get_relevant_documents(prompt)\n",
        "\n",
        "  context_data= \"\"\n",
        "\n",
        "  for document in relevant_documents:\n",
        "    context_data = context_data + \" \" + document.page_content\n",
        "\n",
        "  final_prompt = f\"\"\"Şöyle bir sorum var: {prompt}\n",
        "  Bu soruyu yanıtlamak için elimizde şu bilgiler var: {context_data} .\n",
        "  Bu sorunun yanıtını vermek için yalnızca sana burada verdiğim eldeki bilgileri kullan. Bunların dışına asla çıkma.\n",
        "  \"\"\"\n",
        "\n",
        "  AI_Response = ask_gemini(prompt=final_prompt)\n",
        "\n",
        "  return AI_Response, relevant_documents\n",
        "\n",
        "test_url = \"https://kpmg.com/tr/tr/home/gorusler/2023/12/uretken-yapay-zeka-uygulamalarinin-kurumsallasma-yaklasimi.html\"\n",
        "\n",
        "test_question = \"Üretken yapay zeka uygulamalarının hayata geçirirken yaşanan temel sorunlar neler?\"\n",
        "\n",
        "AI_Response, relevant_documents = rag_with_url(target_url=test_url, prompt=test_question)\n",
        "\n",
        "\n",
        "print(f'SORU: {test_question}')\n",
        "print(\"-\"*100)\n",
        "print(f'YZ YANITI: {AI_Response}')\n",
        "print(\"-*100\")\n",
        "for doc in relevant_documents:\n",
        "  print(doc.page_content)\n",
        "  print(\"-\"*100)\n",
        "  print(doc.metadata)\n",
        "  print(\"*\"*100)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oJriFr2ak6Jo",
        "outputId": "71e43c53-c77a-4985-a050-adb95919d76c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SORU: Üretken yapay zeka uygulamalarının hayata geçirirken yaşanan temel sorunlar neler?\n",
            "----------------------------------------------------------------------------------------------------\n",
            "YZ YANITI: Verilen bilgiler ışığında, üretken yapay zeka uygulamalarının hayata geçirirken yaşanan temel sorunlar şunlardır:\n",
            "\n",
            "* **Yetenek Kazanımı:** Yeterli sayıda yetkin yapay zeka mühendisi bulma zorluğu.\n",
            "* **Yapay Zekaya Güven:** Üretken yapay zekanın güvenilir olmayan sonuçlar üretme potansiyeli.\n",
            "-*100\n",
            "Yetenek Kazanımı: Veri bilimcilerin bile kurumlarda tutundurulmasının zor olduğu bir dünyada üretken yapay zeka alanında yetkinlik sahibi olan yapay zeka mühendislerinin azlığı, sürdürülebilir bir ekip kurma ve bu alanda yeni geliştirmelerin yapılmasında büyük zorluklar yaşattı. \n",
            "Yapay Zekaya Güven: Üretken yapay zekanın ürettiği sonuçların operasyonel bir sistemin karar verme alma noktalarına entegre edildiği noktada, sonucun tutarlılık ve açıklanabilirliği ile ilgili yarattığı güven kaygısı, kritik sistemlerde kullanılmamasına yol açtı. Zira LLM’lerin kural bazlı ya da temel veri bilimi modellerinin aksine “tepki vermeme, sonuç vermeme” yerine “doğru olmasa da mümkün olduğunca geçerli bir sonuç vereyim” motivasyonu kurumlar gibi “sıfır-hata” hedefleyen organizasyonlar için ciddi güven sorunları yarattı.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "{'source': 'https://kpmg.com/tr/tr/home/gorusler/2023/12/uretken-yapay-zeka-uygulamalarinin-kurumsallasma-yaklasimi.html', 'title': 'Üretken Yapay Zeka Uygulamalarının Kurumsallaşma Yaklaş - KPMG Türkiye', 'description': 'Mikro-Dil-Modeli Mimarisi', 'language': 'tr-TR'}\n",
            "****************************************************************************************************\n",
            "İşletmelerde Üretken Yapay Zeka Kullanımları, Yaşanan Zorluklar\n",
            "----------------------------------------------------------------------------------------------------\n",
            "{'source': 'https://kpmg.com/tr/tr/home/gorusler/2023/12/uretken-yapay-zeka-uygulamalarinin-kurumsallasma-yaklasimi.html', 'title': 'Üretken Yapay Zeka Uygulamalarının Kurumsallaşma Yaklaş - KPMG Türkiye', 'description': 'Mikro-Dil-Modeli Mimarisi', 'language': 'tr-TR'}\n",
            "****************************************************************************************************\n",
            "Go to bottom of page\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Home\n",
            "›\n",
            "\n",
            "Görüşler\n",
            "›\n",
            "\n",
            "Üretken Yapay Zeka Uygulamalarının Kurumsallaşma Yaklaşımı\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "19 dakika okunma süresi\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Üretken Yapay Zeka Neden Bu Kadar Popüler Oldu?\n",
            "----------------------------------------------------------------------------------------------------\n",
            "{'source': 'https://kpmg.com/tr/tr/home/gorusler/2023/12/uretken-yapay-zeka-uygulamalarinin-kurumsallasma-yaklasimi.html', 'title': 'Üretken Yapay Zeka Uygulamalarının Kurumsallaşma Yaklaş - KPMG Türkiye', 'description': 'Mikro-Dil-Modeli Mimarisi', 'language': 'tr-TR'}\n",
            "****************************************************************************************************\n",
            "Bu yazıda amaçlanan işletmelerin üretken yapay zeka uygulamalarını ölçeklenebilir seviyede nasıl kullanabilecekleriyle ilgili bir mimari çözüm yaklaşımını aktarmaktır. \n",
            "On-prem açık kaynaklı LLM’lerden LLaMA ve Mistral 7B’nin 7 milyar, bulut üzerinden hizmet veren OpenAI GPT-3’ün 175 milyar, GPT-4’ün ise bilinmeyen büyüklükte parametreye sahip olduğu düşünülürse devasa LLM’lerin organizasyonlarda doğrudan kullanılması çok zordur. \n",
            "Böyle bir üretken yapay zeka uygulaması, gelen değişken talep yoğunluğu, yüksek sayıda eş zamanlı istemci sayıları gibi sadece performans boyutuyla bile bakıldığında çok büyük GPU ve diğer donanım yatırımlarına ihtiyaç duymaktadır. Bu kadar büyük yatırımların zorlayıcı finansal etkisinin yanı sıra işletmelerin sürdürülebilirlik hedeflerinde su ve enerji tüketiminde dünyaya olan olumsuz etkisi de değerlendirilmelidir.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "{'source': 'https://kpmg.com/tr/tr/home/gorusler/2023/12/uretken-yapay-zeka-uygulamalarinin-kurumsallasma-yaklasimi.html', 'title': 'Üretken Yapay Zeka Uygulamalarının Kurumsallaşma Yaklaş - KPMG Türkiye', 'description': 'Mikro-Dil-Modeli Mimarisi', 'language': 'tr-TR'}\n",
            "****************************************************************************************************\n"
          ]
        }
      ]
    }
  ]
}