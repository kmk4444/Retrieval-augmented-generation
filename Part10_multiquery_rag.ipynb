{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMA7REfOaPlHoh0o9BiNZT+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmk4444/Retrieval-augmented-generation/blob/main/Part10_multiquery_rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Requirements.txt**"
      ],
      "metadata": {
        "id": "7mgA3G_RPwQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!touch requirements.txt\n",
        "!echo langchain_community >> requirements.txt\n",
        "!echo langchain >> requirements.txt\n",
        "!echo langchain-openai >> requirements.txt\n",
        "!echo openai >> requirements.txt\n",
        "!echo langchain-google-genai >> requirements.txt\n",
        "!echo cohere >> requirements.txt\n",
        "!echo faiss-cpu >> requirements.txt\n",
        "!echo streamlit >> requirements.txt\n",
        "!echo python-dotenv >> requirements.txt\n",
        "!echo llama-index >> requirements.txt\n",
        "!echo pypdf >> requirements.txt\n",
        "!echo chromadb >> requirements.tx\n",
        "!echo beautifulsoup4 >> requirements.tx\n",
        "!echo matplotlib >> requirements.tx\n",
        "!echo rank_bm25 >> requirements.tx\n",
        "!echo replicate >> requirements.txt"
      ],
      "metadata": {
        "id": "UitqHfTHPxGF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bash/command**"
      ],
      "metadata": {
        "id": "ozfWyLL4P07P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pcJFBRV8M3_s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "7dfe35bf-d1f4-4e4d-f99b-cbcab47af75f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.1.7)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (1.30.1)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.0.5)\n",
            "Requirement already satisfied: cohere in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (5.5.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (1.8.0)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.34.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (1.0.1)\n",
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (0.10.38)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (4.2.0)\n",
            "Requirement already satisfied: replicate in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (0.26.0)\n",
            "Collecting langchain_community (from -r requirements.txt (line 12))\n",
            "  Downloading langchain_community-0.2.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 1)) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 1)) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 1)) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 1)) (0.6.6)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 1)) (0.2.1)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 1)) (0.1.60)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 1)) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 1)) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 1)) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 1)) (8.3.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain-openai->-r requirements.txt (line 2)) (0.7.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai->-r requirements.txt (line 3)) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai->-r requirements.txt (line 3)) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai->-r requirements.txt (line 3)) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai->-r requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai->-r requirements.txt (line 3)) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai->-r requirements.txt (line 3)) (4.11.0)\n",
            "Requirement already satisfied: google-generativeai<0.6.0,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai->-r requirements.txt (line 4)) (0.5.4)\n",
            "Requirement already satisfied: boto3<2.0.0,>=1.34.0 in /usr/local/lib/python3.10/dist-packages (from cohere->-r requirements.txt (line 5)) (1.34.110)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /usr/local/lib/python3.10/dist-packages (from cohere->-r requirements.txt (line 5)) (1.9.4)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from cohere->-r requirements.txt (line 5)) (0.4.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from cohere->-r requirements.txt (line 5)) (0.19.1)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere->-r requirements.txt (line 5)) (2.32.0.20240521)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 7)) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit->-r requirements.txt (line 7)) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 7)) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 7)) (8.1.7)\n",
            "Requirement already satisfied: packaging<25,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 7)) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 7)) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 7)) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 7)) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 7)) (14.0.2)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 7)) (13.7.1)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 7)) (0.10.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 7)) (3.1.43)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 7)) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 7)) (6.3.3)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 7)) (4.0.0)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from llama-index->-r requirements.txt (line 9)) (0.2.5)\n",
            "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index->-r requirements.txt (line 9)) (0.1.12)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.38 in /usr/local/lib/python3.10/dist-packages (from llama-index->-r requirements.txt (line 9)) (0.10.38.post1)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from llama-index->-r requirements.txt (line 9)) (0.1.10)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index->-r requirements.txt (line 9)) (0.1.6)\n",
            "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /usr/local/lib/python3.10/dist-packages (from llama-index->-r requirements.txt (line 9)) (0.9.48)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.13 in /usr/local/lib/python3.10/dist-packages (from llama-index->-r requirements.txt (line 9)) (0.1.20)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from llama-index->-r requirements.txt (line 9)) (0.1.6)\n",
            "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from llama-index->-r requirements.txt (line 9)) (0.1.6)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index->-r requirements.txt (line 9)) (0.1.3)\n",
            "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from llama-index->-r requirements.txt (line 9)) (0.1.22)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse<0.2.0,>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index->-r requirements.txt (line 9)) (0.1.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1)) (1.9.4)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 7)) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 7)) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 7)) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 7)) (0.12.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 3)) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 3)) (1.2.1)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.110 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0.0,>=1.34.0->cohere->-r requirements.txt (line 5)) (1.34.110)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0.0,>=1.34.0->cohere->-r requirements.txt (line 5)) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0.0,>=1.34.0->cohere->-r requirements.txt (line 5)) (0.10.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain->-r requirements.txt (line 1)) (3.21.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain->-r requirements.txt (line 1)) (0.9.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 7)) (4.0.11)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.4 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai->-r requirements.txt (line 4)) (0.6.4)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai->-r requirements.txt (line 4)) (2.11.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai->-r requirements.txt (line 4)) (2.84.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai->-r requirements.txt (line 4)) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai->-r requirements.txt (line 4)) (1.23.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 3)) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 3)) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 3)) (0.14.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain->-r requirements.txt (line 1)) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain->-r requirements.txt (line 1)) (3.10.3)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.38->llama-index->-r requirements.txt (line 9)) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.38->llama-index->-r requirements.txt (line 9)) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.38->llama-index->-r requirements.txt (line 9)) (2023.6.0)\n",
            "Requirement already satisfied: jsonpath-ng in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.38->llama-index->-r requirements.txt (line 9)) (1.6.1)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.38->llama-index->-r requirements.txt (line 9)) (0.1.19)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.38->llama-index->-r requirements.txt (line 9)) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.38->llama-index->-r requirements.txt (line 9)) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.38->llama-index->-r requirements.txt (line 9)) (3.8.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.38->llama-index->-r requirements.txt (line 9)) (3.7.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.38->llama-index->-r requirements.txt (line 9)) (1.14.1)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index->-r requirements.txt (line 9)) (4.12.3)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index->-r requirements.txt (line 9)) (0.0.26)\n",
            "Requirement already satisfied: llama-parse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index->-r requirements.txt (line 9)) (0.4.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit->-r requirements.txt (line 7)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit->-r requirements.txt (line 7)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit->-r requirements.txt (line 7)) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain->-r requirements.txt (line 1)) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain->-r requirements.txt (line 1)) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain->-r requirements.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain->-r requirements.txt (line 1)) (2.0.7)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit->-r requirements.txt (line 7)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit->-r requirements.txt (line 7)) (2.16.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain->-r requirements.txt (line 1)) (3.0.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai->-r requirements.txt (line 2)) (2023.12.25)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<0.20,>=0.19->cohere->-r requirements.txt (line 5)) (0.23.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index->-r requirements.txt (line 9)) (2.5)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 7)) (5.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai->-r requirements.txt (line 4)) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai->-r requirements.txt (line 4)) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.20,>=0.19->cohere->-r requirements.txt (line 5)) (3.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit->-r requirements.txt (line 7)) (2.1.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain->-r requirements.txt (line 1)) (2.4)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 7)) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 7)) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 7)) (0.18.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit->-r requirements.txt (line 7)) (0.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.38->llama-index->-r requirements.txt (line 9)) (1.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit->-r requirements.txt (line 7)) (1.16.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain->-r requirements.txt (line 1)) (1.0.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai->-r requirements.txt (line 4)) (1.63.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai->-r requirements.txt (line 4)) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai->-r requirements.txt (line 4)) (0.1.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai->-r requirements.txt (line 4)) (4.1.1)\n",
            "Requirement already satisfied: ply in /usr/local/lib/python3.10/dist-packages (from jsonpath-ng->llama-index-core<0.11.0,>=0.10.38->llama-index->-r requirements.txt (line 9)) (3.11)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->llama-index-core<0.11.0,>=0.10.38->llama-index->-r requirements.txt (line 9)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->llama-index-core<0.11.0,>=0.10.38->llama-index->-r requirements.txt (line 9)) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->llama-index-core<0.11.0,>=0.10.38->llama-index->-r requirements.txt (line 9)) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->llama-index-core<0.11.0,>=0.10.38->llama-index->-r requirements.txt (line 9)) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->llama-index-core<0.11.0,>=0.10.38->llama-index->-r requirements.txt (line 9)) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy->llama-index-core<0.11.0,>=0.10.38->llama-index->-r requirements.txt (line 9)) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->llama-index-core<0.11.0,>=0.10.38->llama-index->-r requirements.txt (line 9)) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->llama-index-core<0.11.0,>=0.10.38->llama-index->-r requirements.txt (line 9)) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->llama-index-core<0.11.0,>=0.10.38->llama-index->-r requirements.txt (line 9)) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy->llama-index-core<0.11.0,>=0.10.38->llama-index->-r requirements.txt (line 9)) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->llama-index-core<0.11.0,>=0.10.38->llama-index->-r requirements.txt (line 9)) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy->llama-index-core<0.11.0,>=0.10.38->llama-index->-r requirements.txt (line 9)) (6.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->llama-index-core<0.11.0,>=0.10.38->llama-index->-r requirements.txt (line 9)) (67.7.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->llama-index-core<0.11.0,>=0.10.38->llama-index->-r requirements.txt (line 9)) (3.4.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai->-r requirements.txt (line 4)) (1.63.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai->-r requirements.txt (line 4)) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai->-r requirements.txt (line 4)) (3.1.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->llama-index-core<0.11.0,>=0.10.38->llama-index->-r requirements.txt (line 9)) (1.2.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai->-r requirements.txt (line 4)) (0.6.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->llama-index-core<0.11.0,>=0.10.38->llama-index->-r requirements.txt (line 9)) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->llama-index-core<0.11.0,>=0.10.38->llama-index->-r requirements.txt (line 9)) (0.1.4)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy->llama-index-core<0.11.0,>=0.10.38->llama-index->-r requirements.txt (line 9)) (0.16.0)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->llama-index-core<0.11.0,>=0.10.38->llama-index->-r requirements.txt (line 9)) (1.1.1)\n",
            "Installing collected packages: langchain_community\n",
            "Successfully installed langchain_community-0.2.0\n"
          ]
        }
      ],
      "source": [
        "pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile multiqueryhelper.py\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_core.documents import Document\n",
        "import cohere\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "#load_dotenv()\n",
        "\n",
        "#my_key_openai = os.getenv(\"openai_apikey\")\n",
        "#my_key_google = os.getenv(\"google_apikey\")\n",
        "#my_key_cohere = os.getenv(\"cohere_apikey\")\n",
        "\n",
        "my_key_openai=\"---\"\n",
        "my_key_google=\"---\"\n",
        "my_key_cohere=\"---\"\n",
        "\n",
        "llm_gemini = ChatGoogleGenerativeAI(google_api_key=my_key_google, model=\"gemini-pro\")\n",
        "llm_openai = ChatOpenAI(api_key=my_key_openai)\n",
        "embeddings = OpenAIEmbeddings(api_key=my_key_openai)\n",
        "cohere_client = cohere.Client(api_key=my_key_cohere)\n",
        "\n",
        "def generate_multi_query(original_prompt):\n",
        "    multiquery_prompt = f\"\"\"Sen bir yapay zeka asistanısın.\n",
        "\n",
        "    Bir vektör veri tabanından, kullanıcı sorusuna en fazla benzerlik gösteren dokümanların getirilmesi için, sana verilen kullanıcı girdisinin 3 farklı versiyonunu yazmakla görevlisin.\n",
        "\n",
        "    Bunu yaparken amacın ise vektörleri karşılaştırırken kullanılan mesafe ölçümlerinin bazı sınırlılıklarını aşmak için, verilen soruyla ilgili birden çok bakış açısı geliştirerek kullanıcıya yardımcı olmak.\n",
        "\n",
        "    Bu yazacağın alternatif soruları ayrı ayrı satırlarda olacak şekilde yaz.\n",
        "    Alternatif soruları yazarken bunların 1, 2, 3 gibi numaralandırmalar koyma.\n",
        "\n",
        "    Kullanıcı girdisi şöyle: {original_prompt}\"\"\"\n",
        "\n",
        "    generated_queries = llm_openai.invoke(input=multiquery_prompt) # chatbot created several questions.\n",
        "\n",
        "    temp_list = generated_queries.content.strip().split(\"\\n\") # we prepared output for chatbot\n",
        "\n",
        "    #we created a list to save user question and chatbot questions.\n",
        "    query_list = [original_prompt]\n",
        "    query_list.extend(temp_list)\n",
        "\n",
        "    return query_list\n",
        "\n",
        "def get_relevant_documents(target_url,prompt):\n",
        "\n",
        "  loader = WebBaseLoader(target_url)\n",
        "\n",
        "  raw_documents = loader.load()\n",
        "\n",
        "  text_splitter = RecursiveCharacterTextSplitter(\n",
        "      chunk_size=1000,\n",
        "      chunk_overlap=0,\n",
        "      length_function=len\n",
        "  )\n",
        "\n",
        "  splitted_documents = text_splitter.split_documents(raw_documents)\n",
        "\n",
        "  custom_documents=[]\n",
        "\n",
        "  for i, raw_doc in enumerate(splitted_documents):\n",
        "\n",
        "    new_doc = Document(\n",
        "        page_content = raw_doc.page_content,\n",
        "        metadata = {\n",
        "            \"source\" : raw_doc.metadata[\"source\"],\n",
        "            \"title\" : raw_doc.metadata[\"title\"],\n",
        "            \"description\" : raw_doc.metadata[\"description\"],\n",
        "            \"language\" : raw_doc.metadata[\"language\"],\n",
        "            \"doc_id\" : i\n",
        "        }\n",
        "    )\n",
        "\n",
        "    custom_documents.append(new_doc)\n",
        "\n",
        "  vectorstore = FAISS.from_documents(custom_documents,embeddings)\n",
        "  retriever = vectorstore.as_retriever()\n",
        "\n",
        "  relevant_documentss = retriever.get_relevant_documents(prompt)\n",
        "\n",
        "  return relevant_documents\n",
        "\n",
        "def run_rag(relevant_documents, prompt):\n",
        "  context_data = \"\"\n",
        "\n",
        "  for document in relevant_documents:\n",
        "    context_data = context_data + \" \" + document.page_content\n",
        "\n",
        "  final_prompt = f\"\"\"Şöyle bir sorum var: {prompt}\n",
        "  Bu soruyu yanıtlamak için elimizde şu bilgiler var: {context_data} .\n",
        "  Bu sorunun yanıtını vermek için yalnızca sana burada verdiğim eldeki bilgileri kullan. Bunların dışına asla çıkma.\n",
        "  \"\"\"\n",
        "  AI_Response = llm_gemini.invoke(input=final_prompt)\n",
        "\n",
        "  return AI_Response.content\n",
        "\n",
        "def rag_with_url(target_url, prompt):\n",
        "\n",
        "  loader = WebBaseLoader(target_url)\n",
        "\n",
        "  raw_documents = loader.load()\n",
        "\n",
        "  text_splitter = RecursiveCharacterTextSplitter(\n",
        "      chunk_size=1000,\n",
        "      chunk_overlap=0,\n",
        "      length_function=len\n",
        "  )\n",
        "\n",
        "  splitted_documents = text_splitter.split_documents(raw_documents)\n",
        "\n",
        "  custom_documents=[]\n",
        "\n",
        "  for i, raw_doc in enumerate(splitted_documents):\n",
        "\n",
        "    new_doc = Document(\n",
        "        page_content=raw_doc.page_content,\n",
        "        metadata = {\n",
        "            \"source\": raw_doc.metadata[\"source\"],\n",
        "            \"title\": raw_doc.metadata[\"title\"],\n",
        "            \"description\": raw_doc.metadata[\"description\"],\n",
        "            \"language\": raw_doc.metadata[\"language\"],\n",
        "            \"doc_id\":i\n",
        "        }\n",
        "    )\n",
        "\n",
        "    custom_document.append(new_doc)\n",
        "\n",
        "    vectorstore = FAISS.from_documents(custom_documents, embeddings)\n",
        "    retriever = vectorstore.as_retriever()\n",
        "\n",
        "    relevant_documents = retriever.get_relevant_documents(prompt)\n",
        "\n",
        "    context_data = \"\"\n",
        "\n",
        "    for document in relevant_documents:\n",
        "      context_data = context_data + \" \" + document.page_content\n",
        "\n",
        "    final_prompt = f\"\"\"Şöyle bir sorum var: {prompt}\n",
        "    Bu soruyu yanıtlamak için elimizde şu bilgiler var: {context_data} .\n",
        "    Bu sorunun yanıtını vermek için yalnızca sana burada verdiğim eldeki bilgileri kullan. Bunların dışına asla çıkma.\n",
        "    \"\"\"\n",
        "\n",
        "    AI_Response = llm_gemini.invoke(input=final_prompt)\n",
        "\n",
        "    return AI_Response.content, relevant_documents\n",
        "\n",
        "def get_unique_documents(retrieved_documents):\n",
        "\n",
        "  unique_docs = {}\n",
        "\n",
        "  for doc in retrieved_documents:\n",
        "    doc_id = doc.metada[\"doc_id\"]\n",
        "\n",
        "    if doc_id not in unique_docs:\n",
        "      unique_docs[doc_id] = doc\n",
        "\n",
        "  return list(unique_docs.values())\n",
        "\n",
        "def get_reranked_documents(documents, query, document_count=4):\n",
        "\n",
        "  document_contents = []\n",
        "\n",
        "  for doc in documents:\n",
        "    document_contents.append(doc.page_content)\n",
        "\n",
        "  reranked_documents = cohere_client.rerank(\n",
        "      model=\"rerank-multilingual-v2.0\",\n",
        "      query = query,\n",
        "      documents=document_contents,\n",
        "      top_n=document_count\n",
        "  )\n",
        "\n",
        "  reranked_documents_list = []\n",
        "\n",
        "  # for reranked_doc in reranked_documents:\n",
        "  #     reranked_documents_list.append(reranked_doc.document['text'])\n",
        "\n",
        "  for reranked_doc in reranked_documents:\n",
        "    reranked_documents_list.append(documents[reranked_doc.index])\n",
        "\n",
        "  return  reranked_documents_list\n"
      ],
      "metadata": {
        "id": "WqLXyRuwQCXQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile multiquery_rag.py\n",
        "import streamlit as st\n",
        "import multiqueryhelper\n",
        "\n",
        "st.set_page_config(layout=\"wide\")\n",
        "st.title(\"Advanced RAG: Multi-Query | Sorgu Çeşitlendirme ile Bellek Genişletme Örneği\")\n",
        "st.divider()\n",
        "\n",
        "col_input, col_docs, col_uniquedocs, col_rerankeddocs, col_response = st.columns([1,2,2,2,1])\n",
        "\n",
        "with col_input:\n",
        "    target_url = st.text_input(label=\"Hedef Web Adresini Giriniz\", value=\"https://cbarkinozer.medium.com/reg%C3%BCle-edilmemi%C5%9F-yapay-zeka-teknolojileri-kullanman%C4%B1n-tehlikeleri-nelerdir-fa465da15491\")\n",
        "    original_prompt = st.text_input(label=\"Sorunuzu Giriniz:\", value=\"Yapay zeka kullanımının yol açabileceği olumsuz durumlar nelerdir?\")\n",
        "    submit_btn = st.button(label=\"Gönder\")\n",
        "    st.divider()\n",
        "\n",
        "with col_docs:\n",
        "    st.empty()\n",
        "\n",
        "with col_uniquedocs:\n",
        "    st.empty()\n",
        "\n",
        "with col_rerankeddocs:\n",
        "    st.empty()\n",
        "\n",
        "with col_response:\n",
        "    st.empty()\n",
        "\n",
        "if submit_btn:\n",
        "  #Generate alternative queries and show\n",
        "  with st.spinner(\"Soru havuzu oluşturuluyor....\"):\n",
        "    query_list = multiqueryhelper.generate_multi_query(original_prompt=original_prompt)\n",
        "\n",
        "    col_input.markdown(\"SORU HAVUZU\")\n",
        "    st.divider()\n",
        "    for query in query_list:\n",
        "      col_input.markdown(f'**{query}**')\n",
        "\n",
        "  #Get relevant documents for each query and show\n",
        "  retrieved_documents = []\n",
        "\n",
        "  for query in query_list:\n",
        "    relevant_documents = multiqueryhelper.get_relevant_documents(target_url=target_url, prompt=query)\n",
        "\n",
        "    retrieved_documents.extend(relevant_documents)\n",
        "\n",
        "  col_docs.code(f\"Bulunan Doküman Sayısı: {len(retrieved_documents)}\")\n",
        "\n",
        "  for retrieved_doc in retrieved_documents:\n",
        "    col_docs.error(f\"ID: {retrieved_doc.metadata['doc_id']} | {retrieved_doc.page_content}\")\n",
        "\n",
        "  #Get unique documents out of all retrieved documents and show\n",
        "  final_documents = multiqueryhelper.get_unique_documents(retrieved_documents=retrieved_documents)\n",
        "\n",
        "  col_uniquedocs.code(f\"Bulunan Özgün Doküman Sayısı: {len(final_documents)}\")\n",
        "\n",
        "  for final_doc in final_documents:\n",
        "    col_uniquedocs.warning(f\"ID: {final_doc.metadata['doc_id']} | {final_doc.page_content}\")\n",
        "\n",
        "  #Get reranked documents and show\n",
        "\n",
        "  reranked_docs = multiqueryhelper.get_reranked_documents(documents=final_documents, query=original_prompt)\n",
        "\n",
        "  col_rerankeddocs.code(f\"Yeniden Sıralanmış Doküman Sayısı: {len(reranked_docs)}\")\n",
        "\n",
        "  for reranked_doc in reranked_docs:\n",
        "    col_rerankeddocs.info(f\"ID: {reranked_doc.metadata['doc_id']} | {reranked_doc.page_content}\")\n",
        "\n",
        "  #Get AI response and show\n",
        "  AI_Response = multiqueryhelper.run_rag(relevant_documents=reranked_docs, prompt=original_prompt)\n",
        "  col_response.code(\"NİHAİ YANIT\")\n",
        "  col_response.success(AI_Response)\n",
        "\n"
      ],
      "metadata": {
        "id": "7mAn4U-kUuH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel\n",
        "!streamlit run /content/multiquery_rag.py &>/content/logs.txt &\n",
        "!npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "Q6raMf7HchD2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}